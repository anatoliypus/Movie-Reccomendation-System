{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering - Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not have any success with my previous approach, so now I will try Collaborative Filtering approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "from definitions import ROOT_DIR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(ROOT_DIR, 'data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(data_folder, 'data.csv'))\n",
    "films = pd.read_csv(os.path.join(data_folder, 'films.csv'))\n",
    "user = pd.read_csv(os.path.join(data_folder, 'user.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic User-User and Item-Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_ts = data.drop('timestamp', axis=1)\n",
    "sampled = data_no_ts.sample(n=int(data.shape[0] * 0.7))\n",
    "\n",
    "# 0.1 runs 0.3 seconds\n",
    "# 0.2 runs 1.3 seconds\n",
    "# 0.3 runs 3.2 seconds\n",
    "# 0.4 runs 12.2 seconds\n",
    "# 0.5 runs 45.5 seconds\n",
    "# 0.6 runs 138.3 seconds ~ 2 minutes\n",
    "# 0.7 runs 511.7 seconds ~ 8 minutes\n",
    "# 0.8 runs 1893.2 seconds ~ 30 minutes\n",
    "# 0.9 runs 7005.3 seconds ~ 116 minutes\n",
    "# 1.0 runs 21015.9 seconds ~ 350 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(sampled, test_size=0.2)\n",
    "\n",
    "train_data_matrix = train_data.values\n",
    "test_data_matrix = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "user_correlation = 1 - pairwise_distances(train_data, metric='correlation', n_jobs=1)\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "\n",
    "item_correlation = 1 - pairwise_distances(train_data_matrix.T, metric='correlation', n_jobs=1)\n",
    "item_correlation[np.isnan(item_correlation)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict ratings\n",
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        # Use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 140.19990292628052\n",
      "Item-based CF RMSE: 71.1057482132197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def rmse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(pred, actual))\n",
    "# Predict ratings on the training data with both similarity score\n",
    "user_prediction = predict(train_data_matrix, user_correlation, type='user')\n",
    "item_prediction = predict(train_data_matrix, item_correlation, type='item')\n",
    "# RMSE on the train data\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, train_data_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 42, 999,   4],\n",
       "       [592, 482,   4],\n",
       "       [181,   3,   2],\n",
       "       ...,\n",
       "       [846,  12,   5],\n",
       "       [320, 368,   3],\n",
       "       [897, 429,   5]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 288.72855902,  634.18943222,  122.08200876],\n",
       "       [ 546.88854744,  471.01776824,   60.09368432],\n",
       "       [ 343.9601261 ,    1.81789451, -159.77802061],\n",
       "       ...,\n",
       "       [ 569.60240417,  228.12700244,   65.27059339],\n",
       "       [ 378.82982138,  385.92406849,  -73.75388986],\n",
       "       [ 683.53256722,  496.09511678,  151.372316  ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to create a new rating matrix, where rows represent different films and cols represent users. Basically this is a matrix, which maps users ratings to movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 943)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_mat = np.ndarray(\n",
    "    shape=(np.max(data.item_id.values), np.max(data.user_id.values)),\n",
    "    dtype=np.uint8\n",
    ")\n",
    "ratings_mat[data.item_id.values-1, data.user_id.values-1] = data.rating.values\n",
    "ratings_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I am normalizing this matrix and computing its Singular Value Decomposition (SVD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_mat = ratings_mat - np.asarray([(np.mean(ratings_mat, 1))]).T\n",
    "A = normalised_mat.T / np.sqrt(ratings_mat.shape[0] - 1)\n",
    "U, S, V = np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate cosine similarity of films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_cosine_similarity(data, movie_id, top_n=10):\n",
    "    index = movie_id - 1 # Movie id starts from 1 in the dataset\n",
    "    movie_row = data[index, :]\n",
    "    magnitude = np.sqrt(np.einsum('ij, ij -> i', data, data))\n",
    "    similarity = np.dot(movie_row, data.T) / (magnitude[index] * magnitude)\n",
    "    sort_indexes = np.argsort(-similarity)\n",
    "    return sort_indexes[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to print top N similar movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar_movies(movie_data, movie_id, top_indexes):\n",
    "    print('Recommendations for {0}: \\n'.format(\n",
    "    movie_data[movie_data.movie_id == movie_id]['movie title'].values[0]))\n",
    "    for id in top_indexes + 1:\n",
    "        print(movie_data[movie_data.movie_id == id]['movie title'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Richard III (1995): \n",
      "\n",
      "Richard III (1995)\n",
      "Twelfth Night (1996)\n",
      "Losing Chase (1996)\n",
      "Convent, The (Convento, O) (1995)\n",
      "Angels and Insects (1995)\n",
      "Othello (1995)\n",
      "Restoration (1995)\n",
      "In the Bleak Midwinter (1995)\n",
      "Kansas City (1996)\n",
      "Haunted World of Edward D. Wood Jr., The (1995)\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "movie_id = 10 # (getting an id from movies.dat)\n",
    "top_n = 10\n",
    "sliced = V.T[:, :k] # representative data\n",
    "indexes = top_cosine_similarity(sliced, movie_id, top_n)\n",
    "\n",
    "print_similar_movies(films, movie_id, indexes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
